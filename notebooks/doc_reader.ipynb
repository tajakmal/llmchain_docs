{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://python.langchain.com/en/latest/\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"https://python.langchain.com/\"\n",
    "domain_full = domain+\"en/latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all links to local pages on the website\n",
    "\n",
    "local_links = []\n",
    "for link in soup.find_all('a',href=True):\n",
    "    href=link['href']\n",
    "    if href.startswith(domain) or href.startswith('./') \\\n",
    "        or href.startswith('/') or href.startswith('modules') \\\n",
    "        or href.startswith('user_cases'):\n",
    "        local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "# Find the main content using CSS selectors\n",
    "main_content = soup.select('body main')[0]\n",
    "\n",
    "# Extract the HTML code of the main content\n",
    "main_content_html = str(main_content)\n",
    "\n",
    "# Extract the plaintext of the main content\n",
    "main_content_text = main_content.get_text()\n",
    "\n",
    "# Remove all HTML tags\n",
    "main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "# Remove extract white space\n",
    "main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "# Replace HTML entities with their corresponding characters\n",
    "main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "print(main_content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url: str):\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"{res.status_code} for '{url}'\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # Find all links to local pages on the website\n",
    "    local_links = []\n",
    "    for link in soup.find_all('a',href=True):\n",
    "        href=link['href']\n",
    "        if href.startswith(domain) or href.startswith('./') \\\n",
    "            or href.startswith('/') or href.startswith('modules') \\\n",
    "            or href.startswith('user_cases'):\n",
    "            local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "    # Find the main content using CSS selectors\n",
    "    main_content = soup.select('body main')[0]\n",
    "\n",
    "    # Extract the HTML code of the main content\n",
    "    main_content_html = str(main_content)\n",
    "\n",
    "    # Extract the plaintext of the main content\n",
    "    main_content_text = main_content.get_text()\n",
    "\n",
    "    # Remove all HTML tags\n",
    "    main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "    # Remove extract white space\n",
    "    main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "    # Return as JSON\n",
    "    return {\n",
    "        \"url\":url,\n",
    "        \"text\":main_content_text\n",
    "    }, local_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\"https://python.langchain.com/en/latest/\"]\n",
    "scraped = set()\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    if len(links) == 0:\n",
    "        print(\"Complete\")\n",
    "        break\n",
    "    url = links[0]\n",
    "    print(url)\n",
    "    res = scrape(url)\n",
    "    scraped.add(url)\n",
    "    if res is not None:\n",
    "        page_content, local_links = res\n",
    "        data.append(page_content)\n",
    "        # add new links to links list\n",
    "        links.extend(local_links)\n",
    "        # remove duplicates\n",
    "        links = list(set(links))\n",
    "    # remove links \n",
    "    links = [link for link in links if link not in scraped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(data)):\n",
    "    texts = text_splitter.split_text(record['text'])\n",
    "    chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i,\n",
    "        'url': record ['url']\n",
    "    } for i in range(len(texts))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Embedding Model\n",
    "\n",
    "We use text-embedding-ada-002 as the embedding model. We can embed text like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the response res we will find a JSON-like object containing our new embeddings within the 'data' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside 'data' we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains 1536 dimensions - we may just switch to another method of embedding from the other video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to place to store these embeddings and enable a effecient vector search through them all. To do that we use Pinecone, we can get a free API key and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'memory'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see the index is currenlty empty with a total_vector_count of 0. We can begin populating it with OpenAI text-embedding-ada-002 built embeddings like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100 # how many embedding we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoice RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(inpute=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url'] \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieve and then answer generation using GPT-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search through our documents we first need to create a query vector xq. Using xq we retrieve the most relevant chunks from the LancChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taj/development/python/llmchain_docs/.venv/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# After first load you can now just start from here:\n",
    "# POST INITITAL LOAD\n",
    "\n",
    "import pinecone\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables\n",
    "\n",
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1262}},\n",
       " 'total_vector_count': 1262}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POST INITITAL LOAD\n",
    "\n",
    "index_name = 'memory'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'a632cbca-6555-4b51-a01b-0c90162a3c17',\n",
       "              'metadata': {'chunk': 2.0,\n",
       "                           'text': '24626,2006,8155,7381,2,3,15965,872,9626,10008,7,1922,5784,3995,19130,2261,14763,6304,2008,18192,927,14678,4531,14,82,16514,3692,109,1513,899,879,2226,2751,1854,1931,156,8524,2426,721,1021,904,1423,4415,988,3030,426,5684,1411,23,867,2685,4720,1300,504,567,6974,9,184,26,469,2238,5,1648,109,1127,450,6708,5318,1002,258,3392,1991,4,29,212,2,375,537,1046,314,1720,78,890,1861,1,1172,2275,129,29,632,274,599,731,1305,392,307,536,592,87,113,762,845,2552,3788,220,669,3,750,1174,601,310,611,27,54,49,398,51,',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/agents/tools/examples/requests.html'},\n",
       "              'score': 0.756360054,\n",
       "              'values': []},\n",
       "             {'id': '0e2b3ced-633d-44da-83a7-11c27938e725',\n",
       "              'metadata': {'chunk': 2.0,\n",
       "                           'text': 'from langchain.indexes import '\n",
       "                                   'VectorstoreIndexCreator index = '\n",
       "                                   'VectorstoreIndexCreator().from_loaders([loader]) '\n",
       "                                   'Running Chroma using direct local API. '\n",
       "                                   'Using DuckDB in-memory for database. Data '\n",
       "                                   'will be transient. Now that the index is '\n",
       "                                   'created, we can use it to ask questions of '\n",
       "                                   'the data! Note that under the hood this is '\n",
       "                                   'actually doing a few steps as well, which '\n",
       "                                   'we will cover later in this guide. query = '\n",
       "                                   '\"What did the president say about Ketanji '\n",
       "                                   'Brown Jackson\" index.query(query) \" The '\n",
       "                                   'president said that Ketanji Brown Jackson '\n",
       "                                   \"is one of the nation's top legal minds, a \"\n",
       "                                   'former top litigator in private practice, '\n",
       "                                   'a former federal public defender, and from '\n",
       "                                   'a family of public school educators and '\n",
       "                                   'police officers. He also said that she is '\n",
       "                                   'a consensus builder and has received a '\n",
       "                                   'broad range of support from the Fraternal '\n",
       "                                   'Order of Police to former judges appointed '\n",
       "                                   'by Democrats and Republicans.\" query = '\n",
       "                                   '\"What did the president say about Ketanji '\n",
       "                                   'Brown Jackson\" '\n",
       "                                   'index.query_with_sources(query) '\n",
       "                                   \"{'question': 'What did the president say \"\n",
       "                                   \"about Ketanji Brown Jackson', 'answer': \"\n",
       "                                   '\" The president said that he nominated '\n",
       "                                   'Circuit Court of Appeals Judge Ketanji '\n",
       "                                   \"Brown Jackson, one of the nation's top \"\n",
       "                                   \"legal minds, to continue Justice Breyer's \"\n",
       "                                   'legacy of excellence, and that she has '\n",
       "                                   'received',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/getting_started.html'},\n",
       "              'score': 0.745386481,\n",
       "              'values': []},\n",
       "             {'id': '102fe564-3a2c-4037-87ac-c915cb51037e',\n",
       "              'metadata': {'chunk': 0.0,\n",
       "                           'text': '.rst .pdf Indexes Contents Go Deeper '\n",
       "                                   'Indexes# Note Conceptual Guide Indexes '\n",
       "                                   'refer to ways to structure documents so '\n",
       "                                   'that LLMs can best interact with them. '\n",
       "                                   'This module contains utility functions for '\n",
       "                                   'working with documents, different types of '\n",
       "                                   'indexes, and then examples for using those '\n",
       "                                   'indexes in chains. The most common way '\n",
       "                                   'that indexes are used in chains is in a '\n",
       "                                   '“retrieval” step. This step refers to '\n",
       "                                   'taking a user’s query and returning the '\n",
       "                                   'most relevant documents. We draw this '\n",
       "                                   'distinction because (1) an index can be '\n",
       "                                   'used for other things besides retrieval, '\n",
       "                                   'and (2) retrieval can use other logic '\n",
       "                                   'besides an index to find relevant '\n",
       "                                   'documents. We therefor have a concept of a '\n",
       "                                   '“Retriever” interface - this is the '\n",
       "                                   'interface that most chains work with. Most '\n",
       "                                   'of the time when we talk about indexes and '\n",
       "                                   'retrieval we are talking about indexing '\n",
       "                                   'and retrieving unstructured data (like '\n",
       "                                   'text documents). For interacting with '\n",
       "                                   'structured data (SQL tables, etc) or APIs, '\n",
       "                                   'please see the corresponding use case '\n",
       "                                   'sections for links to relevant '\n",
       "                                   'functionality. The primary index and '\n",
       "                                   'retrieval types supported by LangChain are '\n",
       "                                   'currently centered around vector '\n",
       "                                   'databases, and therefore a lot of the '\n",
       "                                   'functionality we dive deep on those '\n",
       "                                   'topics. For an overview',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes.html'},\n",
       "              'score': 0.743674397,\n",
       "              'values': []},\n",
       "             {'id': '84149a52-5c5a-4526-a4c3-85849b7c34e4',\n",
       "              'metadata': {'chunk': 2.0,\n",
       "                           'text': 'Usage '\n",
       "                                   'Tracking\\\\n\\\\n\\\\nIntegrations\\\\nAI21\\\\nAleph '\n",
       "                                   'Alpha\\\\nAnthropic\\\\nAzure OpenAI LLM '\n",
       "                                   'Example\\\\nBanana\\\\nCerebriumAI LLM '\n",
       "                                   'Example\\\\nCohere\\\\nDeepInfra LLM '\n",
       "                                   'Example\\\\nForefrontAI LLM '\n",
       "                                   'Example\\\\nGooseAI LLM Example\\\\nHugging '\n",
       "                                   'Face '\n",
       "                                   'Hub\\\\nManifest\\\\nModal\\\\nOpenAI\\\\nPetals '\n",
       "                                   'LLM Example\\\\nPromptLayer '\n",
       "                                   'OpenAI\\\\nSageMakerEndpoint\\\\nSelf-Hosted '\n",
       "                                   'Models via '\n",
       "                                   'Runhouse\\\\nStochasticAI\\\\nWriter\\\\n\\\\n\\\\nAsync '\n",
       "                                   'API for LLM\\\\nStreaming with '\n",
       "                                   'LLMs\\\\n\\\\n\\\\nReference\\\\n\\\\n\\\\nDocument '\n",
       "                                   'Loaders\\\\nKey Concepts\\\\nHow To '\n",
       "                                   'Guides\\\\nCoNLL-U\\\\nAirbyte '\n",
       "                                   'JSON\\\\nAZLyrics\\\\nBlackboard\\\\nCollege '\n",
       "                                   'Confidential\\\\nCopy Paste\\\\nCSV '\n",
       "                                   'Loader\\\\nDirectory '\n",
       "                                   'Loader\\\\nEmail\\\\nEverNote\\\\nFacebook '\n",
       "                                   'Chat\\\\nFigma\\\\nGCS Directory\\\\nGCS File '\n",
       "                                   'Storage\\\\nGitBook\\\\nGoogle '\n",
       "                                   'Drive\\\\nGutenberg\\\\nHacker '\n",
       "                                   'News\\\\nHTML\\\\niFixit\\\\nImages\\\\nIMSDb\\\\nMarkdown\\\\nNotebook\\\\nNotion\\\\nObsidian\\\\nPDF\\\\nPowerPoint\\\\nReadTheDocs '\n",
       "                                   'Documentation\\\\nRoam\\\\ns3 Directory\\\\ns3 '\n",
       "                                   'File\\\\nSubtitle '\n",
       "                                   'Files\\\\nTelegram\\\\nUnstructured File '\n",
       "                                   'Loader\\\\nURL\\\\nWeb Base\\\\nWord '\n",
       "                                   'Documents\\\\nYouTube\\\\n\\\\n\\\\n\\\\n\\\\nUtils\\\\nKey '\n",
       "                                   'Concepts\\\\nGeneric Utilities\\\\nBash\\\\nBing '\n",
       "                                   'Search\\\\nGoogle Search\\\\nGoogle Serper '\n",
       "                                   'API\\\\nIFTTT WebHooks\\\\nPython '\n",
       "                                   'REPL\\\\nRequests\\\\nSearxNG Search '\n",
       "                                   'API\\\\nSerpAPI\\\\nWolfram Alpha\\\\nZapier '\n",
       "                                   'Natural Language',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html'},\n",
       "              'score': 0.740945578,\n",
       "              'values': []},\n",
       "             {'id': '65b087ee-453a-4f34-8dd2-b359c36a4ece',\n",
       "              'metadata': {'chunk': 8.0,\n",
       "                           'text': \"25), ('Classical 101 - Next Steps', 25), \"\n",
       "                                   \"('Classical 101 - The Basics', 25), \"\n",
       "                                   \"('Grunge', 15), ('Heavy Metal Classic', \"\n",
       "                                   \"26), ('Music', 6580), ('Music Videos', 1)] \"\n",
       "                                   'Thought: I now know the final answer. '\n",
       "                                   'Final Answer: The total number of tracks '\n",
       "                                   \"in each playlist are: '90’s Music' (1477), \"\n",
       "                                   \"'Brazilian Music' (39), 'Classical' (75), \"\n",
       "                                   \"'Classical 101 - Deep Cuts' (25), \"\n",
       "                                   \"'Classical 101 - Next Steps' (25), \"\n",
       "                                   \"'Classical 101 - The Basics' (25), \"\n",
       "                                   \"'Grunge' (15), 'Heavy Metal Classic' (26), \"\n",
       "                                   \"'Music' (6580), 'Music Videos' (1). > \"\n",
       "                                   'Finished chain. \"The total number of '\n",
       "                                   \"tracks in each playlist are: '90’s Music' \"\n",
       "                                   \"(1477), 'Brazilian Music' (39), \"\n",
       "                                   \"'Classical' (75), 'Classical 101 - Deep \"\n",
       "                                   \"Cuts' (25), 'Classical 101 - Next Steps' \"\n",
       "                                   \"(25), 'Classical 101 - The Basics' (25), \"\n",
       "                                   \"'Grunge' (15), 'Heavy Metal Classic' (26), \"\n",
       "                                   '\\'Music\\' (6580), \\'Music Videos\\' (1).\" '\n",
       "                                   'Recovering from an error# In this example, '\n",
       "                                   'the agent is able to recover from an error '\n",
       "                                   'after initially trying to access an '\n",
       "                                   'attribute (Track.ArtistId) which doesn’t '\n",
       "                                   'exist. agent_executor.run(\"Who are the top '\n",
       "                                   '3 best selling',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html'},\n",
       "              'score': 0.740747094,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many namespaces can you have in an index??\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With retrieval complete, we move on to fedding these into GPT-4 to produce answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 is currently accessed via the ChatCompletions endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts alongside our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24626,2006,8155,7381,2,3,15965,872,9626,10008,7,1922,5784,3995,19130,2261,14763,6304,2008,18192,927,14678,4531,14,82,16514,3692,109,1513,899,879,2226,2751,1854,1931,156,8524,2426,721,1021,904,1423,4415,988,3030,426,5684,1411,23,867,2685,4720,1300,504,567,6974,9,184,26,469,2238,5,1648,109,1127,450,6708,5318,1002,258,3392,1991,4,29,212,2,375,537,1046,314,1720,78,890,1861,1,1172,2275,129,29,632,274,599,731,1305,392,307,536,592,87,113,762,845,2552,3788,220,669,3,750,1174,601,310,611,27,54,49,398,51,\n",
      "\n",
      "---\n",
      "\n",
      "from langchain.indexes import VectorstoreIndexCreator index = VectorstoreIndexCreator().from_loaders([loader]) Running Chroma using direct local API. Using DuckDB in-memory for database. Data will be transient. Now that the index is created, we can use it to ask questions of the data! Note that under the hood this is actually doing a few steps as well, which we will cover later in this guide. query = \"What did the president say about Ketanji Brown Jackson\" index.query(query) \" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\" query = \"What did the president say about Ketanji Brown Jackson\" index.query_with_sources(query) {'question': 'What did the president say about Ketanji Brown Jackson', 'answer': \" The president said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, one of the nation's top legal minds, to continue Justice Breyer's legacy of excellence, and that she has received\n",
      "\n",
      "---\n",
      "\n",
      ".rst .pdf Indexes Contents Go Deeper Indexes# Note Conceptual Guide Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains. The most common way that indexes are used in chains is in a “retrieval” step. This step refers to taking a user’s query and returning the most relevant documents. We draw this distinction because (1) an index can be used for other things besides retrieval, and (2) retrieval can use other logic besides an index to find relevant documents. We therefor have a concept of a “Retriever” interface - this is the interface that most chains work with. Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving unstructured data (like text documents). For interacting with structured data (SQL tables, etc) or APIs, please see the corresponding use case sections for links to relevant functionality. The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore a lot of the functionality we dive deep on those topics. For an overview\n",
      "\n",
      "---\n",
      "\n",
      "Usage Tracking\\n\\n\\nIntegrations\\nAI21\\nAleph Alpha\\nAnthropic\\nAzure OpenAI LLM Example\\nBanana\\nCerebriumAI LLM Example\\nCohere\\nDeepInfra LLM Example\\nForefrontAI LLM Example\\nGooseAI LLM Example\\nHugging Face Hub\\nManifest\\nModal\\nOpenAI\\nPetals LLM Example\\nPromptLayer OpenAI\\nSageMakerEndpoint\\nSelf-Hosted Models via Runhouse\\nStochasticAI\\nWriter\\n\\n\\nAsync API for LLM\\nStreaming with LLMs\\n\\n\\nReference\\n\\n\\nDocument Loaders\\nKey Concepts\\nHow To Guides\\nCoNLL-U\\nAirbyte JSON\\nAZLyrics\\nBlackboard\\nCollege Confidential\\nCopy Paste\\nCSV Loader\\nDirectory Loader\\nEmail\\nEverNote\\nFacebook Chat\\nFigma\\nGCS Directory\\nGCS File Storage\\nGitBook\\nGoogle Drive\\nGutenberg\\nHacker News\\nHTML\\niFixit\\nImages\\nIMSDb\\nMarkdown\\nNotebook\\nNotion\\nObsidian\\nPDF\\nPowerPoint\\nReadTheDocs Documentation\\nRoam\\ns3 Directory\\ns3 File\\nSubtitle Files\\nTelegram\\nUnstructured File Loader\\nURL\\nWeb Base\\nWord Documents\\nYouTube\\n\\n\\n\\n\\nUtils\\nKey Concepts\\nGeneric Utilities\\nBash\\nBing Search\\nGoogle Search\\nGoogle Serper API\\nIFTTT WebHooks\\nPython REPL\\nRequests\\nSearxNG Search API\\nSerpAPI\\nWolfram Alpha\\nZapier Natural Language\n",
      "\n",
      "---\n",
      "\n",
      "25), ('Classical 101 - Next Steps', 25), ('Classical 101 - The Basics', 25), ('Grunge', 15), ('Heavy Metal Classic', 26), ('Music', 6580), ('Music Videos', 1)] Thought: I now know the final answer. Final Answer: The total number of tracks in each playlist are: '90’s Music' (1477), 'Brazilian Music' (39), 'Classical' (75), 'Classical 101 - Deep Cuts' (25), 'Classical 101 - Next Steps' (25), 'Classical 101 - The Basics' (25), 'Grunge' (15), 'Heavy Metal Classic' (26), 'Music' (6580), 'Music Videos' (1). > Finished chain. \"The total number of tracks in each playlist are: '90’s Music' (1477), 'Brazilian Music' (39), 'Classical' (75), 'Classical 101 - Deep Cuts' (25), 'Classical 101 - Next Steps' (25), 'Classical 101 - The Basics' (25), 'Grunge' (15), 'Heavy Metal Classic' (26), 'Music' (6580), 'Music Videos' (1).\" Recovering from an error# In this example, the agent is able to recover from an error after initially trying to access an attribute (Track.ArtistId) which doesn’t exist. agent_executor.run(\"Who are the top 3 best selling\n",
      "\n",
      "-----\n",
      "\n",
      "How many namespaces can you have in an index??\n"
     ]
    }
   ],
   "source": [
    "print(augmented_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers user questions based on the information provided by the user above each question. If the information can not be found in the information provided by the user you truthfully say \"I don't know\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this response nicely, we will display it in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we dropped the \"I don't know\" part of the primer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
