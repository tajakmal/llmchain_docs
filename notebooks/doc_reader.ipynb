{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=tBJ-CTKG2dM&t=801s&ab_channel=JamesBriggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(\"https://python.langchain.com/en/latest/\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"https://python.langchain.com/\"\n",
    "domain_full = domain+\"en/latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".rst .pdf Welcome to LangChain Contents Getting Started Modules Use Cases Reference Docs LangChain Ecosystem Additional Resources Welcome to LangChain# LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data Be agentic: allow a language model to interact with its environment The LangChain framework is designed with the above principles in mind. This is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here. Getting Started# Checkout the below guide for a walkthrough of how to get started using LangChain to create an Language Model application. Getting Started Documentation Modules# There are several main modules that LangChain provides support for. For each module we provide some examples to get started, how-to guides, reference docs, and conceptual guides. These modules are, in increasing order of complexity: Models: The various model types and model integrations LangChain supports. Prompts: This includes prompt management, prompt optimization, and prompt serialization. Memory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory. Indexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that. Chains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. Agents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents. Use Cases# The above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports. Autonomous Agents: Autonomous agents are long running agents that take many steps in an attempt to accomplish an objective. Examples include AutoGPT and BabyAGI. Agent Simulations: Putting agents in a sandbox and observing how they interact with each other or to events can be an interesting way to observe their long-term memory abilities. Personal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data. Question Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer. Chatbots: Since language models are good at producing text, that makes them ideal for creating chatbots. Querying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page. Code Understanding: If you want to understand how to use LLMs to query source code from github, you should read this page. Interacting with APIs: Enabling LLMs to interact with APIs is extremely powerful in order to give them more up-to-date information and allow them to take actions. Extraction: Extract structured information from text. Summarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation. Evaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this. Reference Docs# All of LangChain’s reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain. Reference Documentation LangChain Ecosystem# Guides for how other companies/products can be used with LangChain LangChain Ecosystem Additional Resources# Additional collection of resources we think may be useful as you develop your application! LangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents. Glossary: A glossary of all related terms, papers, methods, etc. Whether implemented in LangChain or not! Gallery: A collection of our favorite projects that use LangChain. Useful for finding inspiration or seeing how things were done in other applications. Deployments: A collection of instructions, code snippets, and template repositories for deploying LangChain apps. Tracing: A guide on using tracing in LangChain to visualize the execution of chains and agents. Model Laboratory: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so. Discord: Join us on our Discord to discuss all things LangChain! YouTube: A collection of the LangChain tutorials and videos. Production Support: As you move your LangChains into production, we’d love to offer more comprehensive support. Please fill out this form and we’ll set up a dedicated support Slack channel. next Quickstart Guide Contents Getting Started Modules Use Cases Reference Docs LangChain Ecosystem Additional Resources By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 25, 2023.\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all links to local pages on the website\n",
    "\n",
    "local_links = []\n",
    "for link in soup.find_all('a',href=True):\n",
    "    href=link['href']\n",
    "    if href.startswith(domain) or href.startswith('./') \\\n",
    "        or href.startswith('/') or href.startswith('modules') \\\n",
    "        or href.startswith('user_cases'):\n",
    "        local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "# Find the main content using CSS selectors\n",
    "main_content = soup.select('body main')[0]\n",
    "\n",
    "# Extract the HTML code of the main content\n",
    "main_content_html = str(main_content)\n",
    "\n",
    "# Extract the plaintext of the main content\n",
    "main_content_text = main_content.get_text()\n",
    "\n",
    "# Remove all HTML tags\n",
    "main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "# Remove extract white space\n",
    "main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "# Replace HTML entities with their corresponding characters\n",
    "main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "print(main_content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url: str):\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"{res.status_code} for '{url}'\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # Find all links to local pages on the website\n",
    "    local_links = []\n",
    "    for link in soup.find_all('a',href=True):\n",
    "        href=link['href']\n",
    "        if href.startswith(domain) or href.startswith('./') \\\n",
    "            or href.startswith('/') or href.startswith('modules') \\\n",
    "            or href.startswith('user_cases'):\n",
    "            local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "    # Find the main content using CSS selectors\n",
    "    main_content = soup.select('body main')[0]\n",
    "\n",
    "    # Extract the HTML code of the main content\n",
    "    main_content_html = str(main_content)\n",
    "\n",
    "    # Extract the plaintext of the main content\n",
    "    main_content_text = main_content.get_text()\n",
    "\n",
    "    # Remove all HTML tags\n",
    "    main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "    # Remove extract white space\n",
    "    main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "    # Return as JSON\n",
    "    return {\n",
    "        \"url\":url,\n",
    "        \"text\":main_content_text\n",
    "    }, local_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com/en/latest/\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/bing_search.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/async_llm.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/transformation.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_summarization_checker.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/custom_example_selector.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/requests.html\n",
      "https://python.langchain.com/en/latest/tracing.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/chatgpt_loader.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/srt.html\n",
      "https://python.langchain.com/en/latest/use_cases/question_answering.html\n",
      "https://python.langchain.com/en/latest/modules/agents.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/chat_prompt_template.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory_in_db.html\n",
      "https://python.langchain.com/en/latest/modules/chains.html\n",
      "https://python.langchain.com/en/latest/modules/prompts.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/openapi.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/jira.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/self_ask_with_search.html\n",
      "https://python.langchain.com/en/latest/chat/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/character_text_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/models.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/aleph_alpha.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/hugging_face_dataset.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gutenberg.html\n",
      "https://python.langchain.com/en/latest/use_cases/tabular.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/conversational_customization.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_pipelines.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/token_buffer.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/huggingfacehub.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html\n",
      "https://python.langchain.com/en/latest/glossary.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/vectorstore-retriever.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/adding_memory_chain_multiple_inputs.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/conversational_agent.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/csv.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/intermediate_steps.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notiondb.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/hyde.html\n",
      "https://python.langchain.com/en/latest/use_cases/apis.html\n",
      "https://python.langchain.com/en/latest/use_cases/agent_simulations.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/prompt_serialization.html\n",
      "https://python.langchain.com/en/latest/use_cases/summarization.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_bash.html\n",
      "https://python.langchain.com/en/latest/modules/indexes.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gitbook.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/llm_caching.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/ngram_overlap.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/llm_chain.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/apify.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/myscale.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/gradio_tools.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/weaviate-hybrid.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/deeplake.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/googledrive.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/readthedocs_documentation.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/imsdb.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gcs_directory.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_agent_with_tool_retrieval.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/s3_directory.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/opensearch.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/qdrant.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notebook.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/fake_llm.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/roam.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/analyticdb.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/time_weighted_vectorstore.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/sentence_transformers.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/token_usage_tracking.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/zapier.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/jina.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pgvector.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/length_based.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/elasticsearch.html\n",
      "https://python.langchain.com/en/latest/use_cases/extraction.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/stochasticai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/examples/few_shot_examples.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/sagemaker.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/powerpoint.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/powerbi.html\n",
      "https://python.langchain.com/en/latest/modules/memory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azure_blob_storage_container.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/kg.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
      "https://python.langchain.com/en/latest/use_cases/autonomous_agents.html\n",
      "https://python.langchain.com/en/latest/use_cases/evaluation.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_generation.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_generation.html'\n",
      "https://python.langchain.com/en/latest/evaluation/benchmarking_template.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/benchmarking_template.html'\n",
      "https://python.langchain.com/en/latest/evaluation/data_augmented_question_answering.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/data_augmented_question_answering.html'\n",
      "https://python.langchain.com/en/latest/evaluation/openapi_eval.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/openapi_eval.html'\n",
      "https://python.langchain.com/en/latest/evaluation/agent_benchmarking.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/agent_benchmarking.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/cohere.html\n",
      "https://python.langchain.com/en/latest/memory/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/memory/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/promptlayer_openai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/image_captions.html\n",
      "https://python.langchain.com/en/latest/ecosystem.html\n",
      "https://python.langchain.com/en/latest/llms/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/pal.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/google_serper.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_agent.html\n",
      "https://python.langchain.com/en/latest/deployments.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/CoNLL-U.html\n",
      "https://python.langchain.com/en/latest/use_cases/chatbots.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/atlas.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/comma_separated.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors.html\n",
      "https://python.langchain.com/en/latest/chat/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/memory/types/summary.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/contextual-compression.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azure_blob_storage_file.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/s3_file.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/facebook_chat.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/redis.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/agent_vectorstore.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/max_time_limit.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/diffbot.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/multi_input_tool.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_benchmarking_sota.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_benchmarking_sota.html'\n",
      "https://python.langchain.com/en/latest/evaluation/agent_vectordb_sota_pg.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/agent_vectordb_sota_pg.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/predictionguard.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/word_document.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa_with_sources.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/spacy.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/pandas.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/bilibili.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/buffer.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_multi_action_agent.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/custom_memory.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/entity_summary_memory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/ifixit.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/cohere.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/blockchain.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/html.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/aleph_alpha.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_math.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/google_places.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/telegram.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/latex.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/openapi.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/moderation.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notion.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/pydantic.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/openapi_nla.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/openweathermap.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/bash.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_benchmarking_pg.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_benchmarking_pg.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/youtube.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/async_agent.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/azureopenai.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/summary_buffer.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/milvus.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/writer.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/wikipedia.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/airbyte_json.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/searx_search.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/markdown.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/weaviate.html\n",
      "https://python.langchain.com/en/latest/modules/memory/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/structured.html\n",
      "https://python.langchain.com/en/latest/use_cases/code.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/url.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/petals_example.html\n",
      "https://python.langchain.com/en/latest/evaluation/huggingface_datasets.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/huggingface_datasets.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/banana.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/discord_loader.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/pinecone_hybrid_search.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/self-hosted.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/llm_serialization.html\n",
      "https://python.langchain.com/en/latest/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/similarity.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/replicate.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/examples/streaming.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/git.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/duckdb.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/annoy.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/email.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/anthropic_example.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/partial.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/wolfram_alpha.html\n",
      "https://python.langchain.com/en/latest/evaluation/question_answering.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/question_answering.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/image.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/custom_llm.html\n",
      "https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/bigquery.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/fake.html\n",
      "https://python.langchain.com/en/latest/chains/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/chains/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/huggingface_length_function.html\n",
      "https://python.langchain.com/en/latest/youtube.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl_chat.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/openai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/nltk.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/api.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/obsidian.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/figma.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/human_tools.html\n",
      "https://python.langchain.com/en/latest/model_laboratory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/metal.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/instruct_embeddings.html\n",
      "https://python.langchain.com/en/latest/use_cases/personal_assistants.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/zilliz.html\n",
      "https://python.langchain.com/en/latest/modules/agents/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/whatsapp_chat.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_requests.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/google_search.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/gpt4all.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/blackboard.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/max_iterations.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/tool_input_validation.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gcs_file.html\n",
      "https://python.langchain.com/en/latest/memory/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/memory/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/search_tools.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_text_generation.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/motorhead_memory.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/deepinfra_example.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/custom_tools.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/nlpcloud.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/tensorflowhub.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/ai21.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/chatgpt_clone.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/sequential_chains.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/databerry.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/openai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/copypaste.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/promptlayer_chatopenai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/epub.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/web_base.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/serpapi.html\n",
      "https://python.langchain.com/en/latest/ecosystem/promptlayer.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/tiktoken_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/chatgpt_plugins.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/apify_dataset.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/college_confidential.html\n",
      "https://python.langchain.com/en/latest/getting_started/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/evernote.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/gooseai_example.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azlyrics.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/serialization.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/confluence.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/mmr.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/hn.html\n",
      "https://python.langchain.com/en/latest/evaluation/sql_qa_benchmarking_chinook.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/sql_qa_benchmarking_chinook.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/llamacpp.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/adding_memory.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/buffer_window.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/supabase.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/react.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/cerebriumai_example.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/azure_chat_openai.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/sharedmemory_for_tools.html\n",
      "https://python.langchain.com/en/latest/chat/integrations.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/integrations.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/manifest.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/tiktoken.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/retry.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/redis_chat_message_history.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/llamacpp.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/sagemaker-endpoint.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_chat_agent.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/ddg.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/forefrontai_example.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/postgres_chat_message_history.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/svm_retriever.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/arxiv.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/dataframe.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_mrkl_agent.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/ifttt.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/custom_prompt_template.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/modal.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/from_hub.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/runhouse.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/multiple_memory.html\n",
      "https://python.langchain.com/en/latest/llms/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/getting_started.html'\n",
      "https://python.langchain.com/en/latest/reference.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/tf_idf_retriever.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/vectorstore.html\n",
      "https://python.langchain.com/en/latest/prompt_templates/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/prompt_templates/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/async_chain.html\n",
      "https://python.langchain.com/en/latest/chains/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/chains/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/memory/types/vectorstore_retriever_memory.html\n",
      "https://python.langchain.com/en/latest/modules/chains/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/elastic_search_bm25.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/json.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/csv.html\n",
      "https://python.langchain.com/en/latest/llms/integrations.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/integrations.html'\n",
      "https://python.langchain.com/en/latest/gallery.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/twitter.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/streaming_llm.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/few_shot_examples.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/analyze_document.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/constitutional_chain.html\n",
      "https://python.langchain.com/en/latest/prompt_templates/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/prompt_templates/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_checker.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/slack_directory.html\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "links = [\"https://python.langchain.com/en/latest/\"]\n",
    "scraped = set()\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    if len(links) == 0:\n",
    "        print(\"Complete\")\n",
    "        break\n",
    "    url = links[0]\n",
    "    print(url)\n",
    "    res = scrape(url)\n",
    "    scraped.add(url)\n",
    "    if res is not None:\n",
    "        page_content, local_links = res\n",
    "        data.append(page_content)\n",
    "        # add new links to links list\n",
    "        links.extend(local_links)\n",
    "        # remove duplicates\n",
    "        links = list(set(links))\n",
    "    # remove links \n",
    "    links = [link for link in links if link not in scraped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:02<00:00, 137.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(data)):\n",
    "    texts = text_splitter.split_text(record['text'])\n",
    "    chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i,\n",
    "        'url': record ['url']\n",
    "    } for i in range(len(texts))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Embedding Model\n",
    "\n",
    "We use text-embedding-ada-002 as the embedding model. We can embed text like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the response res we will find a JSON-like object containing our new embeddings within the 'data' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['object', 'data', 'model', 'usage'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside 'data' we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains 1536 dimensions - we may just switch to another method of embedding from the other video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to place to store these embeddings and enable a effecient vector search through them all. To do that we use Pinecone, we can get a free API key and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 4},\n",
       "                'Reseach The Coca Cola Company business model': {'vector_count': 52},\n",
       "                'test-user-1@openai.com': {'vector_count': 4},\n",
       "                'test-user-2@openai.com': {'vector_count': 4},\n",
       "                'test-user-3@openai.com': {'vector_count': 8}},\n",
       " 'total_vector_count': 72}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'bloom'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see the index is currenlty empty with a total_vector_count of 0. We can begin populating it with OpenAI text-embedding-ada-002 built embeddings like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:45<00:00,  6.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100 # how many embedding we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoice RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(inpute=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url'] \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieve and then answer generation using GPT-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search through our documents we first need to create a query vector xq. Using xq we retrieve the most relevant chunks from the LancChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After first load you can now just start from here:\n",
    "# POST INITITAL LOAD\n",
    "\n",
    "import pinecone\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables\n",
    "\n",
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1555},\n",
       "                'Reseach The Coca Cola Company business model': {'vector_count': 52},\n",
       "                'test-user-1@openai.com': {'vector_count': 4},\n",
       "                'test-user-2@openai.com': {'vector_count': 4},\n",
       "                'test-user-3@openai.com': {'vector_count': 8}},\n",
       " 'total_vector_count': 1623}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POST INITITAL LOAD\n",
    "\n",
    "index_name = 'bloom'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'a0daca02-4813-4bb5-b6bb-e303b388a296',\n",
       "              'metadata': {'chunk': 2.0,\n",
       "                           'text': '24626,2006,8155,7381,2,3,15965,872,9626,10008,7,1922,5784,3995,19130,2261,14763,6304,2008,18192,927,14678,4531,14,82,16514,3692,109,1513,899,879,2226,2751,1854,1931,156,8524,2426,721,1021,904,1423,4415,988,3030,426,5684,1411,23,867,2685,4720,1300,504,567,6974,9,184,26,469,2238,5,1648,109,1127,450,6708,5318,1002,258,3392,1991,4,29,212,2,375,537,1046,314,1720,78,890,1861,1,1172,2275,129,29,632,274,599,731,1305,392,307,536,592,87,113,762,845,2552,3788,220,669,3,750,1174,601,310,611,27,54,49,398,51,',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/agents/tools/examples/requests.html'},\n",
       "              'score': 0.756360114,\n",
       "              'values': []},\n",
       "             {'id': '21e87429-9bfe-4c17-90de-1b936d5014b1',\n",
       "              'metadata': {'chunk': 2.0,\n",
       "                           'text': 'from langchain.indexes import '\n",
       "                                   'VectorstoreIndexCreator index = '\n",
       "                                   'VectorstoreIndexCreator().from_loaders([loader]) '\n",
       "                                   'Running Chroma using direct local API. '\n",
       "                                   'Using DuckDB in-memory for database. Data '\n",
       "                                   'will be transient. Now that the index is '\n",
       "                                   'created, we can use it to ask questions of '\n",
       "                                   'the data! Note that under the hood this is '\n",
       "                                   'actually doing a few steps as well, which '\n",
       "                                   'we will cover later in this guide. query = '\n",
       "                                   '\"What did the president say about Ketanji '\n",
       "                                   'Brown Jackson\" index.query(query) \" The '\n",
       "                                   'president said that Ketanji Brown Jackson '\n",
       "                                   \"is one of the nation's top legal minds, a \"\n",
       "                                   'former top litigator in private practice, '\n",
       "                                   'a former federal public defender, and from '\n",
       "                                   'a family of public school educators and '\n",
       "                                   'police officers. He also said that she is '\n",
       "                                   'a consensus builder and has received a '\n",
       "                                   'broad range of support from the Fraternal '\n",
       "                                   'Order of Police to former judges appointed '\n",
       "                                   'by Democrats and Republicans.\" query = '\n",
       "                                   '\"What did the president say about Ketanji '\n",
       "                                   'Brown Jackson\" '\n",
       "                                   'index.query_with_sources(query) '\n",
       "                                   \"{'question': 'What did the president say \"\n",
       "                                   \"about Ketanji Brown Jackson', 'answer': \"\n",
       "                                   '\" The president said that he nominated '\n",
       "                                   'Circuit Court of Appeals Judge Ketanji '\n",
       "                                   \"Brown Jackson, one of the nation's top \"\n",
       "                                   \"legal minds, to continue Justice Breyer's \"\n",
       "                                   'legacy of excellence, and that she has '\n",
       "                                   'received',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/getting_started.html'},\n",
       "              'score': 0.745386541,\n",
       "              'values': []},\n",
       "             {'id': 'be116cb3-5fcd-480f-9eda-046bad33941f',\n",
       "              'metadata': {'chunk': 0.0,\n",
       "                           'text': '.rst .pdf Indexes Contents Go Deeper '\n",
       "                                   'Indexes# Note Conceptual Guide Indexes '\n",
       "                                   'refer to ways to structure documents so '\n",
       "                                   'that LLMs can best interact with them. '\n",
       "                                   'This module contains utility functions for '\n",
       "                                   'working with documents, different types of '\n",
       "                                   'indexes, and then examples for using those '\n",
       "                                   'indexes in chains. The most common way '\n",
       "                                   'that indexes are used in chains is in a '\n",
       "                                   '“retrieval” step. This step refers to '\n",
       "                                   'taking a user’s query and returning the '\n",
       "                                   'most relevant documents. We draw this '\n",
       "                                   'distinction because (1) an index can be '\n",
       "                                   'used for other things besides retrieval, '\n",
       "                                   'and (2) retrieval can use other logic '\n",
       "                                   'besides an index to find relevant '\n",
       "                                   'documents. We therefore have a concept of '\n",
       "                                   'a “Retriever” interface - this is the '\n",
       "                                   'interface that most chains work with. Most '\n",
       "                                   'of the time when we talk about indexes and '\n",
       "                                   'retrieval we are talking about indexing '\n",
       "                                   'and retrieving unstructured data (like '\n",
       "                                   'text documents). For interacting with '\n",
       "                                   'structured data (SQL tables, etc) or APIs, '\n",
       "                                   'please see the corresponding use case '\n",
       "                                   'sections for links to relevant '\n",
       "                                   'functionality. The primary index and '\n",
       "                                   'retrieval types supported by LangChain are '\n",
       "                                   'currently centered around vector '\n",
       "                                   'databases, and therefore a lot of the '\n",
       "                                   'functionality we dive deep on those '\n",
       "                                   'topics. For an overview',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes.html'},\n",
       "              'score': 0.744424224,\n",
       "              'values': []},\n",
       "             {'id': '0af82add-60e4-4897-81f8-1bdd754f8536',\n",
       "              'metadata': {'chunk': 18.0,\n",
       "                           'text': 'this example, we use data from a dataset '\n",
       "                                   'to answer a question from '\n",
       "                                   'langchain.indexes import '\n",
       "                                   'VectorstoreIndexCreator from '\n",
       "                                   'langchain.document_loaders.hugging_face_dataset '\n",
       "                                   'import HuggingFaceDatasetLoader '\n",
       "                                   'dataset_name=\"tweet_eval\" '\n",
       "                                   'page_content_column=\"text\" '\n",
       "                                   'name=\"stance_climate\" '\n",
       "                                   'loader=HuggingFaceDatasetLoader(dataset_name,page_content_column,name) '\n",
       "                                   'index = '\n",
       "                                   'VectorstoreIndexCreator().from_loaders([loader]) '\n",
       "                                   'Found cached dataset tweet_eval Using '\n",
       "                                   'embedded DuckDB without persistence: data '\n",
       "                                   'will be transient query = \"What are the '\n",
       "                                   'most used hashtag?\" result = '\n",
       "                                   \"index.query(query) result ' The most used \"\n",
       "                                   'hashtags in this context are '\n",
       "                                   '#UKClimate2015, #Sustainability, '\n",
       "                                   '#TakeDownTheFlag, #LoveWins, #CSOTA, '\n",
       "                                   '#ClimateSummitoftheAmericas, #SM, and '\n",
       "                                   \"#SocialMedia.' previous HTML next iFixit \"\n",
       "                                   'Contents Example By Harrison Chase © '\n",
       "                                   'Copyright 2023, Harrison Chase. Last '\n",
       "                                   'updated on Apr 25, 2023.',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/hugging_face_dataset.html'},\n",
       "              'score': 0.743554831,\n",
       "              'values': []},\n",
       "             {'id': 'b95933d8-87c9-447e-9f89-2e7c9e69fabf',\n",
       "              'metadata': {'chunk': 5.0,\n",
       "                           'text': 'data will be transient Query# query = '\n",
       "                                   '\"What\\'s the painting about?\" '\n",
       "                                   \"index.query(query) ' The painting is about \"\n",
       "                                   'a battle scene.\\' query = \"What kind of '\n",
       "                                   'images are there?\" index.query(query) \\' '\n",
       "                                   'There are images of a spiral galaxy, a '\n",
       "                                   'painting of a battle scene, a flower in '\n",
       "                                   \"the dark, and a frog on a flower.' \"\n",
       "                                   'previous Images next IMSDb Contents '\n",
       "                                   'Prepare a list of image urls from '\n",
       "                                   'Wikimedia Create the loader Create the '\n",
       "                                   'index Query By Harrison Chase © Copyright '\n",
       "                                   '2023, Harrison Chase. Last updated on Apr '\n",
       "                                   '25, 2023.',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/image_captions.html'},\n",
       "              'score': 0.743213058,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many namespaces can you have in an index??\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With retrieval complete, we move on to fedding these into GPT-4 to produce answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 is currently accessed via the ChatCompletions endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts alongside our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24626,2006,8155,7381,2,3,15965,872,9626,10008,7,1922,5784,3995,19130,2261,14763,6304,2008,18192,927,14678,4531,14,82,16514,3692,109,1513,899,879,2226,2751,1854,1931,156,8524,2426,721,1021,904,1423,4415,988,3030,426,5684,1411,23,867,2685,4720,1300,504,567,6974,9,184,26,469,2238,5,1648,109,1127,450,6708,5318,1002,258,3392,1991,4,29,212,2,375,537,1046,314,1720,78,890,1861,1,1172,2275,129,29,632,274,599,731,1305,392,307,536,592,87,113,762,845,2552,3788,220,669,3,750,1174,601,310,611,27,54,49,398,51,\n",
      "\n",
      "---\n",
      "\n",
      "from langchain.indexes import VectorstoreIndexCreator index = VectorstoreIndexCreator().from_loaders([loader]) Running Chroma using direct local API. Using DuckDB in-memory for database. Data will be transient. Now that the index is created, we can use it to ask questions of the data! Note that under the hood this is actually doing a few steps as well, which we will cover later in this guide. query = \"What did the president say about Ketanji Brown Jackson\" index.query(query) \" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\" query = \"What did the president say about Ketanji Brown Jackson\" index.query_with_sources(query) {'question': 'What did the president say about Ketanji Brown Jackson', 'answer': \" The president said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, one of the nation's top legal minds, to continue Justice Breyer's legacy of excellence, and that she has received\n",
      "\n",
      "---\n",
      "\n",
      ".rst .pdf Indexes Contents Go Deeper Indexes# Note Conceptual Guide Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains. The most common way that indexes are used in chains is in a “retrieval” step. This step refers to taking a user’s query and returning the most relevant documents. We draw this distinction because (1) an index can be used for other things besides retrieval, and (2) retrieval can use other logic besides an index to find relevant documents. We therefore have a concept of a “Retriever” interface - this is the interface that most chains work with. Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving unstructured data (like text documents). For interacting with structured data (SQL tables, etc) or APIs, please see the corresponding use case sections for links to relevant functionality. The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore a lot of the functionality we dive deep on those topics. For an overview\n",
      "\n",
      "---\n",
      "\n",
      "this example, we use data from a dataset to answer a question from langchain.indexes import VectorstoreIndexCreator from langchain.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader dataset_name=\"tweet_eval\" page_content_column=\"text\" name=\"stance_climate\" loader=HuggingFaceDatasetLoader(dataset_name,page_content_column,name) index = VectorstoreIndexCreator().from_loaders([loader]) Found cached dataset tweet_eval Using embedded DuckDB without persistence: data will be transient query = \"What are the most used hashtag?\" result = index.query(query) result ' The most used hashtags in this context are #UKClimate2015, #Sustainability, #TakeDownTheFlag, #LoveWins, #CSOTA, #ClimateSummitoftheAmericas, #SM, and #SocialMedia.' previous HTML next iFixit Contents Example By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 25, 2023.\n",
      "\n",
      "---\n",
      "\n",
      "data will be transient Query# query = \"What's the painting about?\" index.query(query) ' The painting is about a battle scene.' query = \"What kind of images are there?\" index.query(query) ' There are images of a spiral galaxy, a painting of a battle scene, a flower in the dark, and a frog on a flower.' previous Images next IMSDb Contents Prepare a list of image urls from Wikimedia Create the loader Create the index Query By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 25, 2023.\n",
      "\n",
      "-----\n",
      "\n",
      "How many namespaces can you have in an index??\n"
     ]
    }
   ],
   "source": [
    "print(augmented_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers user questions based on the information provided by the user above each question. If the information can not be found in the information provided by the user you truthfully say \"I don't know\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this response nicely, we will display it in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we dropped the \"I don't know\" part of the primer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The number of namespaces you can have in an index varies depending on the system or platform being used. In general, there is no strict limit, but best practices recommend keeping the number of namespaces manageable and organized to ensure optimal performance and maintainability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
