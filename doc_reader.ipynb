{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(\"https://python.langchain.com/en/latest/\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"https://python.langchain.com/\"\n",
    "domain_full = domain+\"en/latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all links to local pages on the website\n",
    "\n",
    "local_links = []\n",
    "for link in soup.find_all('a',href=True):\n",
    "    href=link['href']\n",
    "    if href.startswith(domain) or href.startswith('./') \\\n",
    "        or href.startswith('/') or href.startswith('modules') \\\n",
    "        or href.startswith('user_cases'):\n",
    "        local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "# Find the main content using CSS selectors\n",
    "main_content = soup.select('body main')[0]\n",
    "\n",
    "# Extract the HTML code of the main content\n",
    "main_content_html = str(main_content)\n",
    "\n",
    "# Extract the plaintext of the main content\n",
    "main_content_text = main_content.get_text()\n",
    "\n",
    "# Remove all HTML tags\n",
    "main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "# Remove extract white space\n",
    "main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "# Replace HTML entities with their corresponding characters\n",
    "main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "print(main_content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url: str):\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"{res.status_code} for '{url}'\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # Find all links to local pages on the website\n",
    "    local_links = []\n",
    "    for link in soup.find_all('a',href=True):\n",
    "        href=link['href']\n",
    "        if href.startswith(domain) or href.startswith('./') \\\n",
    "            or href.startswith('/') or href.startswith('modules') \\\n",
    "            or href.startswith('user_cases'):\n",
    "            local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "    # Find the main content using CSS selectors\n",
    "    main_content = soup.select('body main')[0]\n",
    "\n",
    "    # Extract the HTML code of the main content\n",
    "    main_content_html = str(main_content)\n",
    "\n",
    "    # Extract the plaintext of the main content\n",
    "    main_content_text = main_content.get_text()\n",
    "\n",
    "    # Remove all HTML tags\n",
    "    main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "    # Remove extract white space\n",
    "    main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "    # Return as JSON\n",
    "    return {\n",
    "        \"url\":url,\n",
    "        \"text\":main_content_text\n",
    "    }, local_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\"https://python.langchain.com/en/latest/\"]\n",
    "scraped = set()\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    if len(links) == 0:\n",
    "        print(\"Complete\")\n",
    "        break\n",
    "    url = links[0]\n",
    "    print(url)\n",
    "    res = scrape(url)\n",
    "    scraped.add(url)\n",
    "    if res is not None:\n",
    "        page_content, local_links = res\n",
    "        data.append(page_content)\n",
    "        # add new links to links list\n",
    "        links.extend(local_links)\n",
    "        # remove duplicates\n",
    "        links = list(set(links))\n",
    "    # remove links \n",
    "    links = [link for link in links if link not in scraped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(data)):\n",
    "    texts = text_splitter.split_text(record['text'])\n",
    "    chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i,\n",
    "        'url': record ['url']\n",
    "    } for i in range(len(texts))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Embedding Model\n",
    "\n",
    "We use text-embedding-ada-002 as the embedding model. We can embed text like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the response res we will find a JSON-like object containing our new embeddings within the 'data' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside 'data' we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains 1536 dimensions - we may just switch to another method of embedding from the other video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to place to store these embeddings and enable a effecient vector search through them all. To do that we use Pinecone, we can get a free API key and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'gpt-4-langchain-docs'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see the index is currenlty empty with a total_vector_count of 0. We can begin populating it with OpenAI text-embedding-ada-002 built embeddings like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100 # how many embedding we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoice RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(inpute=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url'] \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieve and then answer generation using GPT-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search through our documents we first need to create a query vector xq. Using xq we retrieve the most relevant chunks from the LancChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After first load you can now just start from here:\n",
    "# POST INITITAL LOAD\n",
    "\n",
    "import pinecone\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables\n",
    "\n",
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST INITITAL LOAD\n",
    "\n",
    "index_name = 'gpt-4-langchain-docs'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do I use LLMChain in Langchain?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With retrieval complete, we move on to fedding these into GPT-4 to produce answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 is currently accessed via the ChatCompletions endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts alongside our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(augmented_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers user questions based on the information provided by the user above each question. If the information can not be found in the information provided by the user you truthfully say \"I don't know\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this response nicely, we will display it in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we dropped the \"I don't know\" part of the primer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
