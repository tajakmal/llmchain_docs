{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(\"https://python.langchain.com/en/latest/\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"https://python.langchain.com/\"\n",
    "domain_full = domain+\"en/latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".rst .pdf Welcome to LangChain Contents Getting Started Modules Use Cases Reference Docs LangChain Ecosystem Additional Resources Welcome to LangChain# LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data Be agentic: allow a language model to interact with its environment The LangChain framework is designed with the above principles in mind. This is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here. Getting Started# Checkout the below guide for a walkthrough of how to get started using LangChain to create an Language Model application. Getting Started Documentation Modules# There are several main modules that LangChain provides support for. For each module we provide some examples to get started, how-to guides, reference docs, and conceptual guides. These modules are, in increasing order of complexity: Models: The various model types and model integrations LangChain supports. Prompts: This includes prompt management, prompt optimization, and prompt serialization. Memory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory. Indexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that. Chains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. Agents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents. Use Cases# The above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports. Personal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data. Question Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer. Chatbots: Since language models are good at producing text, that makes them ideal for creating chatbots. Querying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page. Interacting with APIs: Enabling LLMs to interact with APIs is extremely powerful in order to give them more up-to-date information and allow them to take actions. Extraction: Extract structured information from text. Summarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation. Evaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this. Reference Docs# All of LangChain’s reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain. Reference Documentation LangChain Ecosystem# Guides for how other companies/products can be used with LangChain LangChain Ecosystem Additional Resources# Additional collection of resources we think may be useful as you develop your application! LangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents. Glossary: A glossary of all related terms, papers, methods, etc. Whether implemented in LangChain or not! Gallery: A collection of our favorite projects that use LangChain. Useful for finding inspiration or seeing how things were done in other applications. Deployments: A collection of instructions, code snippets, and template repositories for deploying LangChain apps. Tracing: A guide on using tracing in LangChain to visualize the execution of chains and agents. Model Laboratory: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so. Discord: Join us on our Discord to discuss all things LangChain! Production Support: As you move your LangChains into production, we’d love to offer more comprehensive support. Please fill out this form and we’ll set up a dedicated support Slack channel. next Quickstart Guide Contents Getting Started Modules Use Cases Reference Docs LangChain Ecosystem Additional Resources By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 03, 2023.\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all links to local pages on the website\n",
    "\n",
    "local_links = []\n",
    "for link in soup.find_all('a',href=True):\n",
    "    href=link['href']\n",
    "    if href.startswith(domain) or href.startswith('./') \\\n",
    "        or href.startswith('/') or href.startswith('modules') \\\n",
    "        or href.startswith('user_cases'):\n",
    "        local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "# Find the main content using CSS selectors\n",
    "main_content = soup.select('body main')[0]\n",
    "\n",
    "# Extract the HTML code of the main content\n",
    "main_content_html = str(main_content)\n",
    "\n",
    "# Extract the plaintext of the main content\n",
    "main_content_text = main_content.get_text()\n",
    "\n",
    "# Remove all HTML tags\n",
    "main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "# Remove extract white space\n",
    "main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "# Replace HTML entities with their corresponding characters\n",
    "main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "print(main_content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url: str):\n",
    "    res = requests.get(url)\n",
    "    if res.status_code != 200:\n",
    "        print(f\"{res.status_code} for '{url}'\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # Find all links to local pages on the website\n",
    "    local_links = []\n",
    "    for link in soup.find_all('a',href=True):\n",
    "        href=link['href']\n",
    "        if href.startswith(domain) or href.startswith('./') \\\n",
    "            or href.startswith('/') or href.startswith('modules') \\\n",
    "            or href.startswith('user_cases'):\n",
    "            local_links.append(urllib.parse.urljoin(domain_full,href))\n",
    "\n",
    "    # Find the main content using CSS selectors\n",
    "    main_content = soup.select('body main')[0]\n",
    "\n",
    "    # Extract the HTML code of the main content\n",
    "    main_content_html = str(main_content)\n",
    "\n",
    "    # Extract the plaintext of the main content\n",
    "    main_content_text = main_content.get_text()\n",
    "\n",
    "    # Remove all HTML tags\n",
    "    main_content_text = re.sub(r'<[^>]+>','',main_content_text)\n",
    "\n",
    "    # Remove extract white space\n",
    "    main_content_text = ' '.join(main_content_text.split())\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    main_content_text = html.unescape(main_content_text)\n",
    "\n",
    "    # Return as JSON\n",
    "    return {\n",
    "        \"url\":url,\n",
    "        \"text\":main_content_text\n",
    "    }, local_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com/en/latest/\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/evernote.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/constitutional_chain.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html\n",
      "https://python.langchain.com/en/latest/use_cases/summarization.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/copypaste.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/latex.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/token_usage_tracking.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/similarity.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gitbook.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_bash.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azlyrics.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/few_shot_examples.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/ifttt.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/streaming_llm.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/forefrontai_example.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/adding_memory.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/adding_memory_chain_multiple_inputs.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/chatgpt_plugins.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/azureopenai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pgvector.html\n",
      "https://python.langchain.com/en/latest/use_cases/evaluation.html\n",
      "https://python.langchain.com/en/latest/evaluation/data_augmented_question_answering.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/data_augmented_question_answering.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/cohere.html\n",
      "https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/s3_file.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/pal.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/summary.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/multiple_memory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/chatgpt-plugin-retriever.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/nltk.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/openapi.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/token_buffer.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/url.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/duckdb.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/llm_caching.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/redis.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa_with_sources.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/apify.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/serpapi.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/huggingface_hub.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gutenberg.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/ai21.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/react.html\n",
      "https://python.langchain.com/en/latest/modules/agents/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes.html\n",
      "https://python.langchain.com/en/latest/use_cases/question_answering.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_benchmarking_pg.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_benchmarking_pg.html'\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/getting_started.html\n",
      "https://python.langchain.com/en/latest/gallery.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html\n",
      "https://python.langchain.com/en/latest/evaluation/sql_qa_benchmarking_chinook.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/sql_qa_benchmarking_chinook.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/whatsapp_chat.html\n",
      "https://python.langchain.com/en/latest/evaluation/agent_benchmarking.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/agent_benchmarking.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/airbyte_json.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/custom_example_selector.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/custom_llm.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/llm_chain.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/sagemaker-endpoint.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/promptlayer_chatopenai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/readthedocs_documentation.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/wolfram_alpha.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/prompt_serialization.html\n",
      "https://python.langchain.com/en/latest/getting_started/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/ngram_overlap.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/blackboard.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/character_text_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/hn.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters.html\n",
      "https://python.langchain.com/en/latest/modules/memory/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notiondb.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/googledrive.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/powerpoint.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/sharedmemory_for_tools.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/json.html\n",
      "https://python.langchain.com/en/latest/reference.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/length_based.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory_in_db.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/retry.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/zapier.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/vectorstore.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/from_hub.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/zilliz.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_checker.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/promptlayer_openai.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_mrkl_agent.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notion.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/html.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/kg.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/imsdb.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/gooseai_example.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/srt.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/telegram.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/facebook_chat.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/intermediate_steps.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/tiktoken.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/async_llm.html\n",
      "https://python.langchain.com/en/latest/modules/agents.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/csv.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/buffer_window.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/tiktoken_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/wikipedia.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/deeplake.html\n",
      "https://python.langchain.com/en/latest/modules/prompts.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/api.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_chat_agent.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/weaviate.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/structured.html\n",
      "https://python.langchain.com/en/latest/modules/models.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/opensearch.html\n",
      "https://python.langchain.com/en/latest/evaluation/benchmarking_template.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/benchmarking_template.html'\n",
      "https://python.langchain.com/en/latest/modules/models/chat/examples/streaming.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_generation.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_generation.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/manifest.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/epub.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/elasticsearch.html\n",
      "https://python.langchain.com/en/latest/prompt_templates/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/prompt_templates/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/llm_serialization.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/requests.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/comma_separated.html\n",
      "https://python.langchain.com/en/latest/evaluation/agent_vectordb_sota_pg.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/agent_vectordb_sota_pg.html'\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory.html\n",
      "https://python.langchain.com/en/latest/glossary.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/image.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/serialization.html\n",
      "https://python.langchain.com/en/latest/evaluation/huggingface_datasets.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/huggingface_datasets.html'\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/fake.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/openweathermap.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/cerebriumai_example.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/banana.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations.html\n",
      "https://python.langchain.com/en/latest/use_cases/extraction.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/jina.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/sagemaker.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/moderation.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/anthropic_example.html\n",
      "https://python.langchain.com/en/latest/evaluation/qa_benchmarking_sota.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/qa_benchmarking_sota.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/csv.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/output_fixing_parser.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/human_tools.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/figma.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/notebook.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/summary_buffer.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html\n",
      "https://python.langchain.com/en/latest/use_cases/personal_assistants.html\n",
      "https://python.langchain.com/en/latest/deployments.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/searx_search.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/aleph_alpha.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gcs_file.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/spacy.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/custom_prompt_template.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/s3_directory.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/entity_summary_memory.html\n",
      "https://python.langchain.com/en/latest/modules/chains/how_to_guides.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_text_generation.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/self_hosted_examples.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html\n",
      "https://python.langchain.com/en/latest/prompt_templates/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/prompt_templates/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/ecosystem.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/chat_prompt_template.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_summarization_checker.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat.html\n",
      "https://python.langchain.com/en/latest/chat/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/getting_started.html'\n",
      "https://python.langchain.com/en/latest/chat/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/dataframe.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/examples/few_shot_examples.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/hyde.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/search_tools.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/conversational_customization.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/python.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/atlas.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/google_search.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/bigquery.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/modal.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/youtube.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/ifixit.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/custom_tools.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/bash.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/replicate.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/markdown.html\n",
      "https://python.langchain.com/en/latest/chat/integrations.html\n",
      "404 for 'https://python.langchain.com/en/latest/chat/integrations.html'\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/custom_agent.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits/examples/pandas.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/college_confidential.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/async_agent.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/huggingfacehub.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/roam.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_math.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/deepinfra_example.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/petals_example.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html\n",
      "https://python.langchain.com/en/latest/modules/chains.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/bing_search.html\n",
      "https://python.langchain.com/en/latest/use_cases/chatbots.html\n",
      "https://python.langchain.com/en/latest/modules/chains/examples/llm_requests.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/word_document.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/self_ask_with_search.html\n",
      "https://python.langchain.com/en/latest/tracing.html\n",
      "https://python.langchain.com/en/latest/chains/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/chains/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/analyze_document.html\n",
      "https://python.langchain.com/en/latest/chains/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/chains/getting_started.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/transformation.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/azure_openai_example.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/self-hosted.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/apify_dataset.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azure_blob_storage_file.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/instruct_embeddings.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/gcs_directory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/agent_vectorstore.html\n",
      "https://python.langchain.com/en/latest/use_cases/apis.html\n",
      "https://python.langchain.com/en/latest/modules/memory.html\n",
      "https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/writer.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/tensorflowhub.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/example_selectors/examples/mmr.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/redis_chat_message_history.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/max_iterations.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/partial.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl_chat.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/email.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/milvus.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/examples/google_serper.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/openai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/azure_blob_storage_container.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/vectorstore-retriever.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/qdrant.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/huggingface_length_function.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/examples/fake_llm.html\n",
      "https://python.langchain.com/en/latest/modules/memory/types/buffer.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agents/examples/conversational_agent.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/aleph_alpha.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/azure_chat_openai.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html\n",
      "https://python.langchain.com/en/latest/modules/models/llms/integrations/stochasticai.html\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/async_chain.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/web_base.html\n",
      "https://python.langchain.com/en/latest/modules/models/text_embedding/examples/cohere.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/agents/toolkits.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/obsidian.html\n",
      "https://python.langchain.com/en/latest/memory/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/memory/getting_started.html'\n",
      "https://python.langchain.com/en/latest/use_cases/tabular.html\n",
      "https://python.langchain.com/en/latest/modules/chains/getting_started.html\n",
      "https://python.langchain.com/en/latest/modules/models/chat/integrations/openai.html\n",
      "https://python.langchain.com/en/latest/modules/memory/examples/custom_memory.html\n",
      "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/CoNLL-U.html\n",
      "https://python.langchain.com/en/latest/evaluation/question_answering.html\n",
      "404 for 'https://python.langchain.com/en/latest/evaluation/question_answering.html'\n",
      "https://python.langchain.com/en/latest/modules/chains/generic/sequential_chains.html\n",
      "https://python.langchain.com/en/latest/model_laboratory.html\n",
      "https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/chatgpt_clone.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers.html\n",
      "https://python.langchain.com/en/latest/modules/agents/tools/multi_input_tool.html\n",
      "https://python.langchain.com/en/latest/modules/prompts/output_parsers/examples/pydantic.html\n",
      "https://python.langchain.com/en/latest/memory/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/memory/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/modules/models/llms.html\n",
      "https://python.langchain.com/en/latest/llms/integrations.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/integrations.html'\n",
      "https://python.langchain.com/en/latest/llms/how_to_guides.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/how_to_guides.html'\n",
      "https://python.langchain.com/en/latest/llms/getting_started.html\n",
      "404 for 'https://python.langchain.com/en/latest/llms/getting_started.html'\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "links = [\"https://python.langchain.com/en/latest/\"]\n",
    "scraped = set()\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    if len(links) == 0:\n",
    "        print(\"Complete\")\n",
    "        break\n",
    "    url = links[0]\n",
    "    print(url)\n",
    "    res = scrape(url)\n",
    "    scraped.add(url)\n",
    "    if res is not None:\n",
    "        page_content, local_links = res\n",
    "        data.append(page_content)\n",
    "        # add new links to links list\n",
    "        links.extend(local_links)\n",
    "        # remove duplicates\n",
    "        links = list(set(links))\n",
    "    # remove links \n",
    "    links = [link for link in links if link not in scraped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taj/development/python/llmchain_docs/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 272/272 [00:01<00:00, 159.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(data)):\n",
    "    texts = text_splitter.split_text(record['text'])\n",
    "    chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i,\n",
    "        'url': record ['url']\n",
    "    } for i in range(len(texts))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Embedding Model\n",
    "\n",
    "We use text-embedding-ada-002 as the embedding model. We can embed text like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize openai API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the response res we will find a JSON-like object containing our new embeddings within the 'data' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['object', 'data', 'model', 'usage'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside 'data' we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains 1536 dimensions - we may just switch to another method of embedding from the other video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to place to store these embeddings and enable a effecient vector search through them all. To do that we use Pinecone, we can get a free API key and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'gpt-4-langchain-docs'\n",
    "\n",
    "# Initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "\n",
    "# Connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see the index is currenlty empty with a total_vector_count of 0. We can begin populating it with OpenAI text-embedding-ada-002 built embeddings like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:35<00:00,  7.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100 # how many embedding we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoice RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(inpute=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url'] \n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieve and then answer generation using GPT-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search through our documents we first need to create a query vector xq. Using xq we retrieve the most relevant chunks from the LancChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '8c4edbb5-2cf3-43f8-8376-d10590f0a58f',\n",
       "              'metadata': {'chunk': 0.0,\n",
       "                           'text': '.rst .pdf Chains Chains# Note Conceptual '\n",
       "                                   'Guide Using an LLM in isolation is fine '\n",
       "                                   'for some simple applications, but many '\n",
       "                                   'more complex ones require chaining LLMs - '\n",
       "                                   'either with each other or with other '\n",
       "                                   'experts. LangChain provides a standard '\n",
       "                                   'interface for Chains, as well as some '\n",
       "                                   'common implementations of chains for ease '\n",
       "                                   'of use. The following sections of '\n",
       "                                   'documentation are provided: Getting '\n",
       "                                   'Started: A getting started guide for '\n",
       "                                   'chains, to get you up and running quickly. '\n",
       "                                   'How-To Guides: A collection of how-to '\n",
       "                                   'guides. These highlight how to use various '\n",
       "                                   'types of chains. Reference: API reference '\n",
       "                                   'documentation for all Chain classes. '\n",
       "                                   'previous Redis Chat Message History next '\n",
       "                                   'Getting Started By Harrison Chase © '\n",
       "                                   'Copyright 2023, Harrison Chase. Last '\n",
       "                                   'updated on Apr 03, 2023.',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/chains.html'},\n",
       "              'score': 0.87481153,\n",
       "              'values': []},\n",
       "             {'id': '48ea924b-7ba1-41cd-822e-e238f897ec8f',\n",
       "              'metadata': {'chunk': 8.0,\n",
       "                           'text': 'and more. LangChain provides a large '\n",
       "                                   'collection of common utils to use in your '\n",
       "                                   'application.\\\\nChains: Chains go beyond '\n",
       "                                   'just a single LLM call, and are sequences '\n",
       "                                   'of calls (whether to an LLM or a different '\n",
       "                                   'utility). LangChain provides a standard '\n",
       "                                   'interface for chains, lots of integrations '\n",
       "                                   'with other tools, and end-to-end chains '\n",
       "                                   'for common applications.\\\\nIndexes: '\n",
       "                                   'Language models are often more powerful '\n",
       "                                   'when combined with your own text data - '\n",
       "                                   'this module covers best practices for '\n",
       "                                   'doing exactly that.\\\\nAgents: Agents '\n",
       "                                   'involve an LLM making decisions about '\n",
       "                                   'which Actions to take, taking that Action, '\n",
       "                                   'seeing an Observation, and repeating that '\n",
       "                                   'until done. LangChain provides a standard '\n",
       "                                   'interface for agents, a selection of '\n",
       "                                   'agents to choose from, and examples of end '\n",
       "                                   'to end agents.\\\\nMemory: Memory is the '\n",
       "                                   'concept of persisting state between calls '\n",
       "                                   'of a chain/agent. LangChain provides a '\n",
       "                                   'standard interface for memory, a '\n",
       "                                   'collection of memory implementations, and '\n",
       "                                   'examples of chains/agents that use '\n",
       "                                   'memory.\\\\nChat: Chat models are a '\n",
       "                                   'variation on Language Models that expose a '\n",
       "                                   'different API - rather than working with '\n",
       "                                   'raw text, they work with messages. '\n",
       "                                   'LangChain provides a standard interface '\n",
       "                                   'for working with them and doing all the '\n",
       "                                   'same things as above.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html'},\n",
       "              'score': 0.868991137,\n",
       "              'values': []},\n",
       "             {'id': '357fc2cd-1ef5-47ef-9027-ba62d7a8387b',\n",
       "              'metadata': {'chunk': 20.0,\n",
       "                           'text': 'Language models are often more powerful '\n",
       "                                   'when combined with your own text data - '\n",
       "                                   'this module covers best practices for '\n",
       "                                   'doing exactly that.\\\\nChains: Chains go '\n",
       "                                   'beyond just a single LLM call, and are '\n",
       "                                   'sequences of calls (whether to an LLM or a '\n",
       "                                   'different utility). LangChain provides a '\n",
       "                                   'standard interface for chains, lots of '\n",
       "                                   'integrations with other tools, and '\n",
       "                                   'end-to-end chains for common '\n",
       "                                   'applications.\\\\nAgents: Agents involve an '\n",
       "                                   'LLM making decisions about which Actions '\n",
       "                                   'to take, taking that Action, seeing an '\n",
       "                                   'Observation, and repeating that until '\n",
       "                                   'done. LangChain provides a standard '\n",
       "                                   'interface for agents, a selection of '\n",
       "                                   'agents to choose from, and examples of end '\n",
       "                                   'to end agents.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse '\n",
       "                                   'Cases#\\\\nThe above modules can be used in '\n",
       "                                   'a variety of ways. LangChain also provides '\n",
       "                                   'guidance and assistance in this. Below are '\n",
       "                                   'some of the common use cases LangChain '\n",
       "                                   'supports.\\\\n\\\\nPersonal Assistants: The '\n",
       "                                   'main LangChain use case. Personal '\n",
       "                                   'assistants need to take actions, remember '\n",
       "                                   'interactions, and have knowledge about '\n",
       "                                   'your data.\\\\nQuestion Answering: The '\n",
       "                                   'second big LangChain use case. Answering '\n",
       "                                   'questions over specific documents, only '\n",
       "                                   'utilizing the information in those '\n",
       "                                   'documents to construct an '\n",
       "                                   'answer.\\\\nChatbots: Since language models '\n",
       "                                   'are good at producing text,',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html'},\n",
       "              'score': 0.854096234,\n",
       "              'values': []},\n",
       "             {'id': '86d6b543-43fc-4937-98dc-0b827403e1b6',\n",
       "              'metadata': {'chunk': 0.0,\n",
       "                           'text': '.rst .pdf LLMs LLMs# Note Conceptual Guide '\n",
       "                                   'Large Language Models (LLMs) are a core '\n",
       "                                   'component of LangChain. LangChain is not a '\n",
       "                                   'provider of LLMs, but rather provides a '\n",
       "                                   'standard interface through which you can '\n",
       "                                   'interact with a variety of LLMs. The '\n",
       "                                   'following sections of documentation are '\n",
       "                                   'provided: Getting Started: An overview of '\n",
       "                                   'all the functionality the LangChain LLM '\n",
       "                                   'class provides. How-To Guides: A '\n",
       "                                   'collection of how-to guides. These '\n",
       "                                   'highlight how to accomplish various '\n",
       "                                   'objectives with our LLM class (streaming, '\n",
       "                                   'async, etc). Integrations: A collection of '\n",
       "                                   'examples on how to integrate different LLM '\n",
       "                                   'providers with LangChain (OpenAI, Hugging '\n",
       "                                   'Face, etc). Reference: API reference '\n",
       "                                   'documentation for all LLM classes. '\n",
       "                                   'previous Models next Getting Started By '\n",
       "                                   'Harrison Chase © Copyright 2023, Harrison '\n",
       "                                   'Chase. Last updated on Apr 03, 2023.',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/models/llms.html'},\n",
       "              'score': 0.850967526,\n",
       "              'values': []},\n",
       "             {'id': '2f34abfd-69a1-456f-a8e3-9d518ab6ddad',\n",
       "              'metadata': {'chunk': 0.0,\n",
       "                           'text': '.ipynb .pdf Getting Started Contents Why '\n",
       "                                   'do we need chains? Query an LLM with the '\n",
       "                                   'LLMChain Combine chains with the '\n",
       "                                   'SequentialChain Create a custom chain with '\n",
       "                                   'the Chain class Getting Started# In this '\n",
       "                                   'tutorial, we will learn about creating '\n",
       "                                   'simple chains in LangChain. We will learn '\n",
       "                                   'how to create a chain, add components to '\n",
       "                                   'it, and run it. In this tutorial, we will '\n",
       "                                   'cover: Using a simple LLM chain Creating '\n",
       "                                   'sequential chains Creating a custom chain '\n",
       "                                   'Why do we need chains?# Chains allow us to '\n",
       "                                   'combine multiple components together to '\n",
       "                                   'create a single, coherent application. For '\n",
       "                                   'example, we can create a chain that takes '\n",
       "                                   'user input, formats it with a '\n",
       "                                   'PromptTemplate, and then passes the '\n",
       "                                   'formatted response to an LLM. We can build '\n",
       "                                   'more complex chains by combining multiple '\n",
       "                                   'chains together, or by combining chains '\n",
       "                                   'with other components. Query an LLM with '\n",
       "                                   'the LLMChain# The LLMChain is a simple '\n",
       "                                   'chain that takes in a prompt template, '\n",
       "                                   'formats it with the user input and returns '\n",
       "                                   'the response from an LLM. To use the '\n",
       "                                   'LLMChain, first create a prompt template. '\n",
       "                                   'from langchain.prompts import '\n",
       "                                   'PromptTemplate from langchain.llms import '\n",
       "                                   'OpenAI llm = OpenAI(temperature=0.9) '\n",
       "                                   'prompt = PromptTemplate( '\n",
       "                                   'input_variables=[\"product\"], '\n",
       "                                   'template=\"What is a good',\n",
       "                           'url': 'https://python.langchain.com/en/latest/modules/chains/getting_started.html'},\n",
       "              'score': 0.845986307,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how do I use LLMChain in Langchain?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With retrieval complete, we move on to fedding these into GPT-4 to produce answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 is currently accessed via the ChatCompletions endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts alongside our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".rst .pdf Chains Chains# Note Conceptual Guide Using an LLM in isolation is fine for some simple applications, but many more complex ones require chaining LLMs - either with each other or with other experts. LangChain provides a standard interface for Chains, as well as some common implementations of chains for ease of use. The following sections of documentation are provided: Getting Started: A getting started guide for chains, to get you up and running quickly. How-To Guides: A collection of how-to guides. These highlight how to use various types of chains. Reference: API reference documentation for all Chain classes. previous Redis Chat Message History next Getting Started By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 03, 2023.\n",
      "\n",
      "---\n",
      "\n",
      "and more. LangChain provides a large collection of common utils to use in your application.\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\nIndexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\nMemory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\\nChat: Chat models are a variation on Language Models that expose a different API - rather than working with raw text, they work with messages. LangChain provides a standard interface for working with them and doing all the same things as above.\\n\\n\\n\\n\\n\\nUse\n",
      "\n",
      "---\n",
      "\n",
      "Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\n\\n\\n\\n\\n\\nUse Cases#\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\n\\nPersonal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\nQuestion Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\\nChatbots: Since language models are good at producing text,\n",
      "\n",
      "---\n",
      "\n",
      ".rst .pdf LLMs LLMs# Note Conceptual Guide Large Language Models (LLMs) are a core component of LangChain. LangChain is not a provider of LLMs, but rather provides a standard interface through which you can interact with a variety of LLMs. The following sections of documentation are provided: Getting Started: An overview of all the functionality the LangChain LLM class provides. How-To Guides: A collection of how-to guides. These highlight how to accomplish various objectives with our LLM class (streaming, async, etc). Integrations: A collection of examples on how to integrate different LLM providers with LangChain (OpenAI, Hugging Face, etc). Reference: API reference documentation for all LLM classes. previous Models next Getting Started By Harrison Chase © Copyright 2023, Harrison Chase. Last updated on Apr 03, 2023.\n",
      "\n",
      "---\n",
      "\n",
      "prompt serialization. Memory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory. Indexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that. Chains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. Agents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents. Use Cases# The above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports. Personal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data. Question Answering: The\n",
      "\n",
      "-----\n",
      "\n",
      "how do I user the LLMChain in Langchain?\n"
     ]
    }
   ],
   "source": [
    "print(augmented_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers user questions based on the information provided by the user above each question. If the information can not be found in the information provided by the user you truthfully say \"I don't know\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display this response nicely, we will display it in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use the LLMChain in LangChain, follow these steps:\n",
       "\n",
       "1. Import the necessary modules and classes:\n",
       "\n",
       "```python\n",
       "from langchain.prompts import PromptTemplate\n",
       "from langchain.llms import OpenAI\n",
       "from langchain.chains import LLMChain\n",
       "```\n",
       "\n",
       "2. Create and configure an LLM instance (for this example, we use OpenAI):\n",
       "\n",
       "```python\n",
       "llm = OpenAI(temperature=0.9)\n",
       "```\n",
       "\n",
       "3. Create a prompt template with input variables:\n",
       "\n",
       "```python\n",
       "prompt = PromptTemplate(\n",
       "    input_variables=[\"product\"],\n",
       "    template=\"What is a good description of the product {product}?\"\n",
       ")\n",
       "```\n",
       "\n",
       "4. Initialize the LLMChain with the LLM instance and the prompt template:\n",
       "\n",
       "```python\n",
       "chain = LLMChain(llm=llm, prompt_template=prompt)\n",
       "```\n",
       "\n",
       "5. Pass the input as a dictionary to the `run` method of the LLMChain and retrieve the response:\n",
       "\n",
       "```python\n",
       "input_data = {\"product\": \"smartphone\"}\n",
       "response = chain.run(input_data)\n",
       "print(response)\n",
       "```\n",
       "\n",
       "This example demonstrates how to use the LLMChain in LangChain with an OpenAI LLM and a custom prompt template. Adapt the LLM instance or the prompt template to suit your specific use case."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we dropped the \"I don't know\" part of the primer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
